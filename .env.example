# =============================================================================
# YT-TRANSCRIBER CONFIGURATION
# =============================================================================

# =========================
# WHISPER (Transcription via faster-whisper / CTranslate2)
# =========================
# Model: any HuggingFace ID (base, small, medium, large-v3, distil-large-v3, turbo)
# tiny/base: ~1GB RAM | small: ~2GB | medium: ~5GB | large-v3: ~6GB (int8_float16)
WHISPER_MODEL_NAME=base

# Device: auto (detects CUDA via CTranslate2), cpu, or cuda
WHISPER_DEVICE=auto

# Compute type: default (auto: int8_float16 GPU, int8 CPU), or explicit
# WHISPER_COMPUTE_TYPE=default

# Beam search: 1=greedy (fast), 5=default (quality)
# WHISPER_BEAM_SIZE=5

# Silero VAD: skips silence automatically (faster transcription)
# WHISPER_VAD_FILTER=true

# =========================
# CLAUDE CLI (for AI features: summaries, translations, post kits)
# =========================
# Uses Claude Code CLI (requires `claude` in PATH with active subscription)
# CLAUDE_CLI_PATH=claude
# CLAUDE_CLI_TIMEOUT=180
# DEFAULT_LLM_MODEL=sonnet

# =========================
# LLM MODEL SELECTION (opus/sonnet/haiku)
# =========================
SUMMARIZER_MODEL=sonnet
TRANSLATOR_MODEL=haiku

# =========================
# DIRECTORIES
# =========================
LOG_LEVEL=INFO
TEMP_DOWNLOAD_DIR=temp_files/
OUTPUT_TRANSCRIPTS_DIR=output/transcripts/
SUMMARY_OUTPUT_DIR=output/summaries/

# =========================
# TRANSCRIPT CACHING
# =========================
# Transcript caching (reuse transcripts for same video)
TRANSCRIPT_CACHE_ENABLED=false
TRANSCRIPT_CACHE_DIR=output/analysis/transcripts_cache/

# =========================
# POST KITS (LinkedIn + Twitter)
# =========================
POST_KITS_LINKEDIN_MIN_CHARS=800
POST_KITS_LINKEDIN_MAX_CHARS=1200
POST_KITS_TWITTER_MIN_TWEETS=8
POST_KITS_TWITTER_MAX_TWEETS=12
